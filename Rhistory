stat.desc(props$Vis_eng)
stat.desc(concs$Aud_eng)
stat.desc(concs$Hap_eng)
stat.desc(concs$Vis_eng)
psych::describe(props$Aud_eng)
psych::describe(props$Hap_eng)
psych::describe(props$Vis_eng)
psych::describe(concs$Aud_eng)
psych::describe(concs$Hap_eng)
psych::describe(concs$Vis_eng)
summaryBy(Aud_eng ~ main_eng, data=props, FUN=mean)
summaryBy(Hap_eng ~ main_eng, data=props, FUN=mean)
summaryBy(Vis_eng ~ main_eng, data=props, FUN=mean)
# concepts
summaryBy(Aud_eng ~ main_eng, data=concs, FUN=mean)
summaryBy(Hap_eng ~ main_eng, data=concs, FUN=mean)
summaryBy(Vis_eng ~ main_eng, data=concs, FUN=mean)
summaryBy(exc_eng ~ main_eng, data=props, FUN=mean)
summaryBy(exc_eng ~ main_eng, data=concs, FUN=mean)
# Modalities
rcor.test(props[, c('Auditory', 'Aud_eng')], use = 'complete.obs')
rcor.test(props[, c('Haptic', 'Hap_eng')], use = 'complete.obs')
rcor.test(props[, c('Visual', 'Vis_eng')], use = 'complete.obs')
# Significant, large correlations ranging from .69 to .80
# Exclusivity 
rcor.test(props[, c('Exclusivity', 'exc_eng')], use = 'complete.obs')
## CONCEPTS
# Modalities
rcor.test(concs[, c('Auditory', 'Aud_eng')], use = 'complete.obs')
rcor.test(concs[, c('Haptic', 'Hap_eng')], use = 'complete.obs')
rcor.test(concs[, c('Visual', 'Vis_eng')], use = 'complete.obs')
# Significant, large correlations ranging from .63 to .69
# Exclusivity 
rcor.test(concs[, c('Exclusivity', 'exc_eng')], use = 'complete.obs')
psych::describe(props$Auditory)
psych::describe(props$Haptic)
psych::describe(props$Visual)
psych::describe(concs$Auditory)
psych::describe(concs$Haptic)
psych::describe(concs$Visual)
psych::describe(props$Aud_eng)
psych::describe(props$Hap_eng)
psych::describe(props$Vis_eng)
psych::describe(concs$Aud_eng)
psych::describe(concs$Hap_eng)
psych::describe(concs$Vis_eng)
stat.desc(props$Aud_eng)
stat.desc(props$Hap_eng)
stat.desc(props$Vis_eng)
stat.desc(concs$Aud_eng)
stat.desc(concs$Hap_eng)
stat.desc(concs$Vis_eng)
# properties
summaryBy(Aud_eng ~ main_eng, data=props, FUN=mean)
summaryBy(Hap_eng ~ main_eng, data=props, FUN=mean)
summaryBy(Vis_eng ~ main_eng, data=props, FUN=mean)
summaryBy(exc_eng ~ main_eng, data=props, FUN=mean)
# Properties
psych::describe(props$exc_eng)      # M = 0.48
psych::describe(props$Exclusivity)  # M = 0.40
# Concepts
psych::describe(concs$exc_eng)      # M = 0.40
psych::describe(concs$Exclusivity)  # M = 0.29
# Properties
t.test(props$exc_eng, mu = 0.40)
# The difference is considerable, t(734) = 18.8, p < .001
# dz = t/vn = 0.47
# Concepts
t.test(concs$exc_eng, mu = 0.29)
rcor.test(props[, c('Aud_eng', 'Hap_eng', 'Vis_eng', 'exc_eng')], use = 'complete.obs')
corr3 = rcor.test(props[, c('Aud_eng', 'Hap_eng', 'Vis_eng', 'exc_eng')], use = 'complete.obs')
write.csv(corr3$cor.mat, file = "corr3.csv",na="") # find table in your working dir
# CONCEPTS
rcor.test(concs[, c('Aud_eng', 'Hap_eng', 'Vis_eng', 'exc_eng')], use = 'complete.obs')
corr4 = rcor.test(concs[, c('Aud_eng', 'Hap_eng', 'Vis_eng', 'exc_eng')], use = 'complete.obs')
write.csv(corr4$cor.mat, file = "corr4.csv",na="") # find table in your working dir
# Setting contrasts based on means
contrasts(all$main) <- cbind(c(2,0,-2), c(-1,2,-1))
# (1) Aud vs Vis; (2) Hap vs Aud-&-Vis
contrasts(all$main)
fitt <- aov(Exclusivity ~ main * cat, data=all)
plot(fitt)  # must click over the plot several times in order to continue
summary(fitt)
Anova(fitt)
Anova(fitt, type = "II")
Anova(fitt, type = "III")
Anova(fitt, type = "IV")
summary.lm(fitt)
t.test(props$exc_eng, mu = 0.40)
# The difference is considerable, t(734) = 18.8, p < .001
# dz = t/vn = 0.47
# Concepts
t.test(concs$exc_eng, mu = 0.29)
# Below, very informative plots based on Principal Components Analysis (PCA), 
# as in Lynott and Connell (2009, 2013)
# Firstly it is performed on the Dutch norms, then on the English ones, leaving out gustatory
# and olfactory ratings/words. At the end, Dutch and English plots are compared.
all <- read.csv('all.csv')
str(all) # 747 used in Dutch norms + English not used
# ON DUTCH NORMS
# # properties
# check conditions for a PCA
# matrix
prop <- all[all$cat == 'prop', c('Auditory', 'Haptic', 'Visual')]
str(prop)
prop_matrix <- cor(prop, use = 'complete.obs')
prop_matrix
round(prop_matrix, 2)
# POOR: correlations not apt for a PCA, with too many below .3
# now on the raw vars:
prop
cortest.bartlett(prop)
# GOOD: Bartlett's test significant 
# KMO: Kaiser-Meyer-Olkin Measure of Sampling Adequacy
KMO(prop_matrix)
# Result: .56 = mediocre. PCA not strongly recommended. But we still do it
# because the purpose is graphical only.
# check determinant
det(prop_matrix)
# GOOD: >0.00001
# start off with unrotated PCA
pc1_prop <- principal(prop, nfactors = 3, rotate = "none")
pc1_prop
# RESULT: Only RC1, with eigenvalue > 1, should be extracted, 
all <- read.csv('all.csv')
str(all) # 747 used in Dutch norms + English not used
# ON DUTCH NORMS
# # properties
# check conditions for a PCA
# matrix
prop <- all[all$cat == 'prop', c('Auditory', 'Haptic', 'Visual')]
str(prop)
prop_matrix <- cor(prop, use = 'complete.obs')
prop_matrix
round(prop_matrix, 2)
# POOR: correlations not apt for a PCA, with too many below .3
# now on the raw vars:
prop
cortest.bartlett(prop)
# GOOD: Bartlett's test significant 
# KMO: Kaiser-Meyer-Olkin Measure of Sampling Adequacy
KMO(prop_matrix)
# Result: .56 = mediocre. PCA not strongly recommended. But we still do it
# because the purpose is graphical only.
# check determinant
det(prop_matrix)
# GOOD: >0.00001
# start off with unrotated PCA
pc1_prop <- principal(prop, nfactors = 3, rotate = "none")
pc1_prop
# RESULT: Only RC1, with eigenvalue > 1, should be extracted, 
# acc to Kaiser's criterion (Jolliffe's threshold of 0.7 way too lax; 
# Field, Miles, & Field, 2012)
# Unrotated: scree plot
# Result: one or two RCs should be extracted, converging with eigenvalues
# Now with varimax rotation, Kaiser-normalized (by default). 
# Always preferable because it captures explained variance best. 
# Compare eigenvalues w/ 1 & 2 factors
pc2_prop <- principal(prop, nfactors = 2, rotate = "varimax", scores = TRUE)
pc2_prop
pc2_prop$loadings
# good to extract 2 factors, as they both explain quite the same variance,
Rc2_conc
Rc2_conc
Rc2_conc
rc2_conc
RC2_conc
# We needed to plot their data differently from the plots on their papers in order to 
# properly compare our norms. Simply, we excluded what was not relevant to our norms, 
# namely the olfactory and gustatory modality ratings, and the words with such 
# dominant modalities. 
# #  ENG PROPERTIES
# check conditions for a PCA
# matrix
eng_prop <- all[all$cat == 'prop', c('Aud_eng', 'Hap_eng', 'Vis_eng')]
str(eng_prop)
eng_prop_matrix <- cor(eng_prop, use = 'complete.obs')
eng_prop_matrix
round(eng_prop_matrix, 2)
# OK: correlations good for a PCA, with enough < .3
# now on the raw vars:
eng_prop
cortest.bartlett(eng_prop)
# GOOD: Bartlett's test significant 
# KMO: Kaiser-Meyer-Olkin Measure of Sampling Adequacy
KMO(eng_prop_matrix)
# Result: .56 = mediocre. PCA not strongly recommended. But we still do it
# because the purpose is graphical only.
# check determinant
det(eng_prop_matrix)
# GOOD: >0.00001
# start off with unrotated PCA
pc1_eng_prop <- principal(eng_prop, nfactors = 3, rotate = "none")
pc1_eng_prop
# RESULT: Extract either one PC, acc to Kaiser's criterion, or two RCs, acc to Joliffe's
# (Field, Miles, & Field, 2012)
# Unrotated: scree plot
plot(pc1_eng_prop$values, type = "b")
# Result: again one or two RCs should be extracted
# Now with varimax rotation, Kaiser-normalized (by default)
pc2_eng_prop <- principal(eng_prop, nfactors = 2, rotate = "varimax", scores = TRUE)
pc2_eng_prop
pc2_eng_prop$loadings
# two components are good, as they both have eigenvalues over 1
pc2_eng_prop$residual
# #  ENG CONCEPTS
# check conditions for a PCA
# matrix
eng_conc <- all[all$cat == 'conc', c('Aud_eng', 'Hap_eng', 'Vis_eng')]
str(eng_conc)
eng_conc_matrix <- cor(eng_conc, use = 'complete.obs')
eng_conc_matrix
round(eng_conc_matrix, 2)
# POOR: correlations not apt for a PCA, with too many below .3
# now on the raw data:
eng_conc
cortest.bartlett(eng_conc)
# GOOD: Bartlett's test significant 
# KMO: Kaiser-Meyer-Olkin Measure of Sampling Adequacy
KMO(eng_conc_matrix)
# Result: .48 = poor. PCA not strongly recommended. But we still do it
# because the purpose is graphical really.
# check determinant
det(eng_conc_matrix)
# GOOD: >0.00001
# start off with unrotated PCA
pc1_eng_conc <- principal(eng_conc, nfactors = 3, rotate = "none")
pc1_eng_conc
# RESULT: Extract either one RC, acc to Kaiser's criterion, or two RCs, acc to Joliffe's
# (Field, Miles, & Field, 2012)
# Unrotated: scree plot
plot(pc1_eng_conc$values, type = "b")
# Result: two PCs obtain.
# Now with varimax rotation, Kaiser-normalized (by default):
# always preferable because it captures explained variance best. 
pc2_eng_conc <- principal(eng_conc, nfactors = 2, rotate = "varimax", scores = TRUE)
pc2_eng_conc
pc2_eng_conc$loadings
pc2_eng_conc
pc2_eng_conc$loadings
pc2_eng_conc$residual
pc2_eng_conc$fit
pc2_eng_conc$communality
# Results based on a Kaiser-normalizalized orthogonal (varimax) rotation 
# (by default in psych::stats). Residuals bad: over 50% have absolute 
# values > 0.05. Model fit good, > .90. Communalities good, all > .7.
# subset and add PCs
eng_concs <- all[all$cat == 'conc', ]
str(eng_concs)
eng_concs <- cbind(eng_concs, pc2_eng_conc$scores)
summary(eng_concs$RC1, eng_concs$RC2)
eng_concs <- eng_concs[eng_concs$normed == 'Dut_Eng' | eng_concs$normed == 'English',]
str(eng_concs)
summary(eng_concs$RC1, eng_concs$RC2)
# # Finally, plot
Engconcs <- ggplot(eng_concs,
  aes(RC1, RC2, label = as.character(main_eng))) +
  aes (x = RC1, y = RC2, by = main_eng) + stat_density2d (color = "gray87") +
  geom_text(size = 7) +
    ggtitle ('English concepts') +
    theme_bw() +    # theme with white background
    theme(    # clear background, gridlines, chart border
    plot.background = element_blank()
   ,panel.grid.major = element_blank()
   ,panel.grid.minor = element_blank()
   ,panel.border = element_blank()
  ) +
  theme(axis.line = element_line(color = 'black')) +  # draw x and y lines
    theme(axis.title.x = element_text(colour = 'black', size = 23, 
margin=margin(15,15,15,15)),
         axis.title.y = element_text(colour = 'black', size = 23, 
margin=margin(15,15,15,15)),
         axis.text.x  = element_text(size=16),
   axis.text.y  = element_text(size=16)) +
  labs(x = "Rotated PCA factor 1", y = "Rotated PCA factor 2") +
    theme(plot.title = element_text(size = 32, face = "bold", 
margin=margin(15,15,15,15)))
#  Now to save, run first line below and return to keep running. See your folder.
png(file="Engconcs_highres.png", units="in", width=13, height=13, res=900)
plot(Engconcs)
dev.off()
png(file="allfour_highres.png", units="in", width=19, height=19, res=1200)
multiplot(Engprops4, Engconcs, NLprops4, NLconcs2, cols = 2)
# warning normal: just those English items that were not used in Dutch
dev.off()
png(file="proppair_highres.png", units="in", width=18, height=9, res=1000)
multiplot(Engprops, NLprops2, cols = 2)
# warning normal: just those English items that were not used in Dutch
dev.off()
png(file="concpair_highres.png", units="in", width=18, height=9, res=1000)
multiplot(Engconcs, NLconcs2, cols = 2)
# warning normal: just those English items that were not used in Dutch
dev.off()
# ICONICITY
# Last tests: iconicity/sound symbolism on concepts and properties separately.
# Regressions include same lexical vars (DVs) as Lynott and Connell, plus 
# concreteness and AoA.
# Note that the selection is based on p-value thresholds, as in L&C, but also on
# AIC, which is a bayesian, relative method more appropriate with such a large
# sample. Importantly, AIC and F/p-value criteria resulted in the same inclusions 
# and exclusions for every regression.
# For both props and concs, we start with PCA with all lexical variables in order
# to isolate them, because they are intercorrelated (see Table 5 in Lynott & Connell,
# 2013)
all <- read.csv('all.csv')
str(all)
# Length is 759 but only 747 are from these norms. Rest are from Lynott and Connell 
# (2009, 2013) for comparative analyses. These extra items do not have an id number 
# in the file. 
# Iconicity within concepts alone, as in Lynott and Connell (2013)
concs <- all[all$cat == 'conc' & c(all$normed == 'Dutch' | all$normed == 'Dut_Eng'),]
str(concs)
q()
q()
rmarkdown::render("norms.R", "pdf_document")
install.packages('principal')
library(principal)
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", "pdf_document")
q()
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", "pdf_document")
# To render HTML and PDF reports
rmarkdown::render("norms.R", "pdf_document")
Anova(fitt, type = "IV")
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", "html_document")
rmarkdown::render("norms.R", "html_document")
obs(props)  # 366 Dutch + a few from Lynott&Connell for comparisons
complete.cases(props)  # 366 Dutch + a few from Lynott&Connell for comparisons
!is.na(props)  # 366 Dutch + a few from Lynott&Connell for comparisons
n(props)  # 366 Dutch + a few from Lynott&Connell for comparisons
nrow(props)  # 366 Dutch + a few from Lynott&Connell for comparisons
counts
nrow(allNL$section)
allNL$section
str(allNL$section)
nrow(concs)
nrow(corrs_props)
str(corrs_props)
nrow(props)
nrow(allNL$catmain)
str(allNL$catmain)
counts
nrow(prop)
nrow(eng_conc)
PCA_lexicals_concs
str(lexicals_props)
PCA_lexicals_props
rmarkdown::render("norms.R", "html_document")
rmarkdown::render("norms.R", "pdf_document")
?rmarkdown::render
rmarkdown::render("norms.R", "pdf_document", output_file = NULL)
rmarkdown::render("norms.R", "pdf_document", comment=NA, output_file = NULL)
rmarkdown::render("norms.R", "pdf_document", output_file = 
"Modality exclusivity norms for 747 properties and concepts in Dutch")
multiplot(Engprops, NLprops2, cols = 2)
NLprops
rmarkdown::render("norms.R", "pdf_document", output_file = 
"Modality exclusivity norms for 747 properties and concepts in Dutch")
rmarkdown::render("norms.R", "pdf_document", output_file = 
Modality exclusivity norms for 747 properties and concepts in Dutch)
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", "pdf_document")
rmarkdown::render("norms.R", c("pdf_document", "html_document"))
NormsWeb <- rpubsUpload(title='Modality exclusivity norms for 747 properties 
and concepts in Dutch: a replication of English',htmlFile=
'norms.html',method=getOption('rpubs.upload.method','auto')
'norms.html',method=getOption('rpubs.upload.method','auto')
library(markdown)
NormsWeb <- rpubsUpload(title='Modality exclusivity norms for 747 properties 
and concepts in Dutch: a replication of English',htmlFile=
'norms.html',method=getOption('rpubs.upload.method','auto')
'norms.html',method=getOption('rpubs.upload.method','auto')
NormsWeb <- rpubsUpload(title='Modality exclusivity norms for 747 properties 
and concepts in Dutch: a replication of English',htmlFile=
'norms.html',method=getOption('rpubs.upload.method','auto'))
result <- rpubsUpload(title='Modality exclusivity norms for 747 properties 
and concepts in Dutch: a replication of English',htmlFile=
'norms.html',method=getOption('rpubs.upload.method','auto'))
?rpubsUpload
rpubsUpload('Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English', 'norms.html', id = NULL, properties = list(comments=NA), 
    method = getOption("rpubs.upload.method", "auto"))
rpubsUpload('Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English', 'norms.html', id = NULL, properties = list(), 
    method = getOption("rpubs.upload.method", "auto"))
result <- rpubsUpload("Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English", "norms.html")
if (!is.null(result$continueUrl)) 
    browseURL(result$continueUrl) else stop(result$error)
kjnkans <- rpubsUpload("Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English", "norms.html")
if (!is.null(result$continueUrl)) 
    browseURL(result$continueUrl) else stop(result$error)
kjnkans <- rpubsUpload("Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English", "norms.html")
if (!is.null(result$continueUrl)) 
    browseURL(result$continueUrl) else stop(result$error))
kjnkans <- rpubsUpload("Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English", "norms.html")
if (!is.null(result$continueUrl)) 
    browseURL(result$continueUrl) else stop(result$error)
result <- rpubsUpload("Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English", "norms.html")
rpubsUpload('Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses/norms.html',
 id = NULL, properties = list(), 
    method = getOption("rpubs.upload.method", "auto"))
rpubsUpload('Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses/norms.html',
 id = NULL, properties = list(), 
    method = getOption("curl"))
rpubsUpload('Modality exclusivity norms for 747 properties and concepts in Dutch: 
a replication of English', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses/norms.html',
 id = NULL, properties = list(), 
    method = getOption("auto"))
rpubsUpload('norms', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses.html',
 id = NULL, properties = list(), 
    method = getOption("rpubs.upload.method", "auto"))
rpubsUpload('norms.html', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses.html',
 id = NULL, properties = list(), 
    method = getOption("rpubs.upload.method", "auto"))
rpubsUpload('norms.html', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses',
 id = NULL, properties = list(), 
    method = getOption("rpubs.upload.method", "auto"))
rpubsUpload('norms', 
'C:/Users/Pablo/Dropbox/STUDIES/R/Experiment Data/responses',
 id = NULL, properties = list(), 
    method = getOption("rpubs.upload.method", "auto"))
q()
a_concs<-concs[, c('a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9')]
psych::alpha(a_concs)
props$a10
rmarkdown::render("norms.R", c("pdf_document", "html_document"))
rmarkdown::render("norms.R", c("pdf_document", "html_document"))
readPNG('proppair_highres.png', native = T, info = FALSE)
library(png)
install.packages('png')
library(png)
readPNG('proppair_highres.png', native = T, info = FALSE)
plot(i1)
i1 = readPNG('proppair_highres.png', native = T, info = FALSE)
plot(i1)
i1 = readPNG('proppair_highres.png', native = F, info = FALSE)
plot(i1)
i1 = readPNG('proppair_highres.png', native = T, info = FALSE)
)
rmarkdown::render("norms.R", "pdf_document")
q()
q()
q()
q()
plot(Engprops)  # ! THE PLOT IS SHOWN BADLY ON HERE. PLEASE SEE THE SAVED PLOT
Engprops  # ! THE PLOT IS SHOWN BADLY ON HERE. PLEASE SEE THE SAVED PLOT
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
mat_lexicals_props <- as.matrix(props[c('letters', 'phonemes_DUTCHPOND', 'orth_neighbours_DUTCHPOND', 
'phon_neighbours_DUTCHPOND', 'freq_lg10CD_SUBTLEXNL', 'freq_lg10WF_SUBTLEXNL', 'freq_CELEX_lem',
'AoA_Brysbaertetal2014', 'concrete_Brysbaertetal2014')])
rcor.test(mat_lexicals_props, use='complete.obs')
rcor.test(mat_lexicals_props, use='complete.obs')
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
q()
source('NLprops_highres.png')
source('NLprops_highres')
source(NLprops_highres)
source(NLprops_highres.png)
read.png(NLprops_highres.png)
read.png('NLprops_highres.png')
library(png)
read.png('NLprops_highres.png')
read.PNG('NLprops_highres.png')
readPNG('NLprops_highres.png')
rmarkdown::render("norms.R", "pdf_document") # rendering for a few minutes
rmarkdown::render("norms.R", "word_document") # rendering for a few minutes
rmarkdown::render("norms.R", "word_document") # rendering for a few minutes
rmarkdown::render("norms.R", "word_document") # rendering for a few minutes
q()
q()
rmarkdown::render("norms.R", c("word_document", "pdf_document")) 
s
step_orth_neighbours_DUTCHPOND_concs_AIC <- stepAIC(fit_orth_neighbours_DUTCHPOND_
concs, direction="both")
step_orth_neighbours_DUTCHPOND_concs_AIC <- stepAIC(fit_orth_neighbours_DUTCHPOND_concs, direction="both")
step_orth_neighbours_DUTCHPOND_concs_AIC <- 
stepAIC(fit_orth_neighbours_DUTCHPOND_concs, direction="both")
fit_freq_lg10CD_SUBTLEXNL_concs <- lm(concs$s_freq_lg10CD_SUBTLEXNL ~ 
concs$s_Auditory + concs$s_Haptic + concs$s_Visual, data = concs)
rmarkdown::render("norms.R", c("word_document", "pdf_document")) 
rmarkdown::render("norms.R", c("word_document", "pdf_document"))
rmarkdown::render("norms.R", c("word_document", "pdf_document"))
rmarkdown::render("norms.R", c("word_document", "pdf_document"))
rmarkdown::render("norms.R", c("word_document", "pdf_document"))
rmarkdown::render("norms.R", c("word_document", "pdf_document"))
rmarkdown::render("norms.R", c("word_document", "pdf_document"))
q()
